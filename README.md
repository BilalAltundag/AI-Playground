![Uploading image.pngâ€¦]()

# ğŸ§  AI & LLM Learning Journey

Bu depo, Yapay Zeka ve **BÃ¼yÃ¼k Dil Modelleri (LLM)** mimarilerini derinlemesine anlamak amacÄ±yla geliÅŸtirdiÄŸim projeleri ve teknik notlarÄ± iÃ§erir.  
HazÄ±r API'lerin Ã¶tesine geÃ§erek, modellerin Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±nÄ± (**backend / matematik**) seviyesinde **sÄ±fÄ±rdan inÅŸa etmeyi** hedefler.

---

## ğŸš€ Proje 1: Baby GPT â€“ SÄ±fÄ±rdan Transformer EÄŸitimi

Bu proje, modern dil modellerinin (**GPT-4, LLaMA, Mistral** vb.) temelini oluÅŸturan **Transformer mimarisinin**,  
**PyTorch kullanÄ±larak sÄ±fÄ±rdan kodlanmÄ±ÅŸ ve eÄŸitilmiÅŸ** bir versiyonudur.

HazÄ±r *Trainer* kÃ¼tÃ¼phaneleri kullanÄ±lmadan;

- Self-Attention mekanizmasÄ±  
- Multi-Head Attention yapÄ±sÄ±  
- Tokenization sÃ¼reci  

manuel olarak inÅŸa edilmiÅŸtir.

Model, diyalog verisi Ã¼zerinde eÄŸitilerek **basit bir chatbot** fonksiyonu kazanmÄ±ÅŸtÄ±r.

â–¶ï¸ **Projeyi Google Colab'de Ä°ncele ve Ã‡alÄ±ÅŸtÄ±r**  
*(link eklenebilir)*

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

- **Core:** Python, PyTorch (CUDA)
- **Tokenizer:** Tiktoken (OpenAI BPE)
- **Data:** Hugging Face â€“ `knkarthick/dialogsum`
- **Deployment:** Gradio

---

## ğŸ“Š Model Ã–zeti (Safe Pro Config)

*T4 GPU sÄ±nÄ±rlarÄ± iÃ§inde optimize edilmiÅŸ model yapÄ±landÄ±rmasÄ±*

| Parametre | DeÄŸer | AÃ§Ä±klama |
|---------|------|---------|
| **Model Tipi** | Decoder-only Transformer | GPT mimarisi |
| **Parametre SayÄ±sÄ±** | ~10 Milyon | Custom boyutta eÄŸitildi |
| **Context Window** | 192 Token | HafÄ±za derinliÄŸi |
| **Embedding Size** | 384 | Katman geniÅŸliÄŸi |
| **Layers / Heads** | 6 Blok / 6 Kafa | Derinlik ve paralellik |

---

## ğŸ“‰ SonuÃ§

Model **5000 adÄ±m** boyunca eÄŸitilmiÅŸ ve  
**CrossEntropyLoss** deÄŸeri **~4.5 â†’ ~0.5** seviyesine dÃ¼ÅŸÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

Bu sonuÃ§, modelin:

- Ä°ngilizce gramer yapÄ±sÄ±nÄ±  
- Temel diyalog mantÄ±ÄŸÄ±nÄ±  

baÅŸarÄ±yla Ã¶ÄŸrendiÄŸini gÃ¶stermektedir.

---

## ğŸ—ºï¸ Roadmap (Gelecek Hedefler)

- [x] SÄ±fÄ±rdan Transformer Mimarisi (Baby GPT)
- [ ] BÃ¼yÃ¼k bir modelin (LLaMA-3 / Mistral) **Fine-Tuning** iÅŸlemi
- [ ] **RAG (Retrieval Augmented Generation)** ile dÃ¶kÃ¼man tabanlÄ± sohbet
- [ ] **Vision Transformer (ViT)** entegrasyonu
